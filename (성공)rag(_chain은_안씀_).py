# -*- coding: utf-8 -*-
"""(성공)rag(_chain은_안씀_).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d62iqlO_vYm0H0SToSH3XSUUqb2Jhl_0

### 라이브러리 다운로드
"""

# Commented out IPython magic to ensure Python compatibility.
# # open ai 업데이트되면서 이거 해야함 나중에는 뺄 것
# %%capture
# !pip install httpx==0.27.2 --force-reinstall --quiet

#코랩에서 한다면 이걸로
!pip install langchain_openai
!pip install langchain
!pip install langchain_community
!pip install datasets
!pip install sentence_transformers
!pip install faiss-gpu
#!pip install langchain_openai
#!pip install openai==0.28
#!pip install langchain_openai
!pip install -U transformers
#!pip install streamlit pyngrok
!pip install huggingface_hub
!pip install pypdf
!pip install beautifulsoup4
!pip install pandas
!pip install torch

from langchain_community.embeddings import HuggingFaceEmbeddings
import bs4
from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma, FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

from datasets import load_dataset

"""#faiss불러오기(법률)



"""

from huggingface_hub import login
import pandas as pd
login("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")

from huggingface_hub import hf_hub_download
import os

path_1 = '/content/test_1'
#교수님께서 경로 설정을 해주셔야 합니다!


for filenames in ['index.pkl','index.faiss']:
  test_1 = (hf_hub_download(repo_id='sungjinny/all_law_embedding', filename= filenames, cache_dir=path_1))


test_1 = os.path.dirname(test_1)

from langchain_community.embeddings import HuggingFaceBgeEmbeddings
embeddings_model = HuggingFaceBgeEmbeddings(model_name="intfloat/multilingual-e5-large-instruct")
vectorstors_1 = FAISS.load_local(test_1, embeddings_model, allow_dangerous_deserialization = True)


retriever_1 = vectorstors_1.as_retriever(search_type="similarity", search_kwargs = { 'k' :3})

"""#faiss불러오기 (판례)

"""

from huggingface_hub import login
import pandas as pd
login("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")

from huggingface_hub import hf_hub_download
import os

path_2 = '/content/test_2'
#교수님께서 경로 설정을 해주셔야 합니다!


for filenames in ['index.pkl','index.faiss']:
  test_2 = (hf_hub_download(repo_id='sungjinny/precedent_embedding', filename= filenames, cache_dir=path_2))


test_2 = os.path.dirname(test_2)

from langchain_community.embeddings import HuggingFaceBgeEmbeddings
embeddings_model = HuggingFaceBgeEmbeddings(model_name="intfloat/multilingual-e5-large-instruct")
vectorstors_precedent = FAISS.load_local(test_2, embeddings_model, allow_dangerous_deserialization = True)


retriever_precedent = vectorstors_precedent.as_retriever(search_type="similarity", search_kwargs = { 'k' :3})

"""# hugging face 사용 (법률)

"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'
model_id_token = 'Bllossom/llama-3.2-Korean-Bllossom-3B'
tokenizer = AutoTokenizer.from_pretrained(model_id_token)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

import time

def explain_law(search_result):
    """법 내용을 쉽게 요약하여 설명"""

    law_name = search_result.metadata
    law_content = search_result.page_content

    messages = [
        {"role": "system", "content": "당신은 assistant(법조인)입니다. {law}에 들어있는 {content}를 사용자가 쉽게 이해할 수 있도록 2줄로 요약해 주세요."},
        {"role": "law", "content": f"법률 이름: {law_name}, 법률 내용: {law_content}"},
        {"role": "assistant", "content": ""}
    ]

    input_ids = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt"
    ).to(model.device)

    terminators = [
        tokenizer.convert_tokens_to_ids("<|end_of_text|>"),
        tokenizer.convert_tokens_to_ids("<|eot_id|>")
    ]


    outputs = model.generate(
        input_ids,
        max_new_tokens=512,
        eos_token_id=terminators,
        do_sample=True,
        temperature=0.6,
        top_p=0.9
    )


    ai_message = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)


    return ai_message


def judge_guilty_or_not(result, explanation, user_situation):
    """법 설명에 기반하여 유죄 여부 판단"""
    law_name = result.metadata
    law_content = result.page_content

    messages = [
        {"role": "system", "content": """당신은 전문 판사입니다. 사용자의 상황과 관련 '법률 내용'과 '법률 설명'을 검토하여 위법 여부를 판단합니다.
             사용자 상황이 법률이름과 관련이 없다면 {'관련 법이 아닙니다'}라고 대답해.\n
             관련이 있다면 사용자 상황이 법률 내용을 위반했는지 여부를 판단하고, 위반 여부와 이유를 2줄로 설명해.
        )"""},
        {"role": "user", "content":
            f"사용자 상황: {user_situation}\n"
            f"법률 이름: {law_name}\n"
            f"법률 내용: {law_content}\n"
            f"법률 설명: {explanation}\n"
            },
        {"role": "assistant", "content": ""}
    ]

    input_ids = tokenizer.apply_chat_template(
        messages,
        add_generation_prompt=True,
        return_tensors="pt"
    ).to(model.device)

    terminators = [
        tokenizer.convert_tokens_to_ids("<|end_of_text|>"),
        tokenizer.convert_tokens_to_ids("<|eot_id|>")
    ]

    outputs = model.generate(
        input_ids,
        max_new_tokens=512,
        eos_token_id=terminators,
        do_sample=True,
        temperature=0.6,
        top_p=0.9
    )


    ai_message = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)

    return ai_message


# 사용자 입력
user_situation = input("당신이 처한 상황에 대해 말해주세요: ")
print("--------------------------------------------------------")

# 검색된 법률 문서
search_result = retriever_1.get_relevant_documents(user_situation)

for result in search_result:
    start_time = time.time()
    print('법률:',result.metadata)
    print('내용:',result.page_content)
    explanations = explain_law(result)
    judgments = judge_guilty_or_not(result, explanations, user_situation)
    print('법 설명입니다:',explanations)
    print('범죄 성립 유무입니다:',judgments)
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"대답을 받는데 걸린 시간: {elapsed_time:.4f} 초")
    print("--------------------------------------------------------")

query = "나는 이번에 주식 유튜브를 통해 사람들을 모았고, 사람들의 계좌를 내가 관리해준다고 받았어. 그렇게 처음에는 수익 인증을 해주다가 한 달 정도 지난 후에 그 돈으로 내가 작전주를 사서 내 주식을 높은 가격에 샀어. 혹시 문제가 될까?"
print(retriever_1.get_relevant_documents(query))
a = retriever_1.get_relevant_documents(query)
print(a[0].metadata)
print(a[0].page_content)

"""# gpt api 사용 (법률)


"""

import os
os.environ['OPENAI_API_KEY'] = 'sk-nWr1XASAX6oiKDTP5w2Vz66LGB33p2foo68KSBBf-4T3BlbkFJ_B2hiZOr_4drw7Fo2eXz-WBzuhN57wnwmjgPxIAAQA'


from langchain_openai import ChatOpenAI
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

import time
from langchain_core.prompts import PromptTemplate
def explain_law(search_result):
    """법 내용을 쉽게 요약하여 설명"""

    law_name = search_result.metadata
    law_content = search_result.page_content
    prompt = PromptTemplate.from_template("당신은 전문변호사 입니다. {law_name}과 {law_content}를 일반인이 보고 쉽게 이해할 수 있도록 2줄로 요약해주세요")


    chain = prompt | llm
    ai_message = chain.invoke(
        {
            "law_name": law_name,
            "law_content": law_content,

        }
    )
    return ai_message


def judge_guilty_or_not(result, explanation, user_situation):
    """법 설명에 기반하여 유죄 여부 판단"""
    law_name = result.metadata
    law_content = result.page_content

    prompt = PromptTemplate.from_template("당신은 전문판사 입니다. {law_name}과 {law_content} 가 {user_situation}와 관련이 있는지 확인하고 관련이 없다면 '관련이 없는 법입니다'. 대부분은 관련이 없어. 사용자의 직업, 장소 등을 고려해서 객관적으로 판단해. 관련이 있다면 사용자가 {law_content}를 위반했는지 여부를 판단하고, 위반 여부와 이유를 2줄로 설명해. ")


    chain = prompt | llm
    ai_message = chain.invoke(
        {   "user_situation": user_situation,
            "law_name": law_name,
            "law_content": law_content,

        }
    )



    return ai_message


# 사용자 입력
user_situation = input("당신이 처한 상황에 대해 말해주세요: ")
print("--------------------------------------------------------")

# 검색된 법률 문서
search_result = retriever_1.get_relevant_documents(user_situation)

for result in search_result:
    start_time = time.time()
    print('법률:',result.metadata)
    print('내용:',result.page_content)
    explanations = explain_law(result)
    judgments = judge_guilty_or_not(result, explanations, user_situation)
    print('법 설명입니다:',explanations.content)
    print('범죄 성립 유무입니다:',judgments.content)
    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"대답을 받는데 걸린 시간: {elapsed_time:.4f} 초")
    print("--------------------------------------------------------")

"""# gpt api 사용 (판례)

"""

import os
os.environ['OPENAI_API_KEY'] = 'sk-nWr1XASAX6oiKDTP5w2Vz66LGB33p2foo68KSBBf-4T3BlbkFJ_B2hiZOr_4drw7Fo2eXz-WBzuhN57wnwmjgPxIAAQA'


from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

import time
from langchain_core.prompts import PromptTemplate

def answer_precedent(user_situaiton):



    prompt = PromptTemplate.from_template("{user_situation}의 글을 판시사항 형식으로 3줄 미만으로 요약해서 줘")

    chain = prompt | llm
    ai_message = chain.invoke(
        {   "user_situation": user_situation,
        }
    )
    print('변환된 사용자의 질문:',ai_message.content)
    "----------------------------------------------------------------------------------"
    search_with_ai = retriever_precedent.get_relevant_documents(f'{ai_message}')
    return search_with_ai

def ai_summary(content):

    prompt = PromptTemplate.from_template("주어진{content}는 판시사항이야 일반인이 이해하기 쉽도록 쉬운 말로 1줄로 요약해")

    chain = prompt | llm
    ai_message = chain.invoke(
        {   "content": content,
        }
    )

    return ai_message


user_situation = input("검색할 판례의 내용을 입력하세요: ")
print("--------------------------------------------------------")

ai_search = answer_precedent(user_situation)
normall_search = retriever_precedent.get_relevant_documents(user_situation)

all_search = ai_search + normall_search

content = []
link = []

for i in range(len(all_search)):
  content.append(c[i].page_content)
  link.append(c[i].metadata)

content = list(set(content))
link = list(set(link['link'] for link in link))
for i in range(len(content)):
  print('내용:',content[i])
  print('요약:',ai_summary(content[i]).content)
  print('url:',link[i])
  print("--------------------------------------------------------")
  memory = ai_summary(content[i])


# 검색된 법률 문서

print(memory.content)

"""#gpt합치기 (법률 서비스, 판례 서비스)찾기

"""

import os
os.environ['OPENAI_API_KEY'] = 'sk-nWr1XASAX6oiKDTP5w2Vz66LGB33p2foo68KSBBf-4T3BlbkFJ_B2hiZOr_4drw7Fo2eXz-WBzuhN57wnwmjgPxIAAQA'


from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

import time
from langchain_core.prompts import PromptTemplate

# 법률 관련 기능
def explain_law(search_result):
    """법 내용을 쉽게 요약하여 설명"""
    law_name = search_result.metadata
    law_content = search_result.page_content
    prompt = PromptTemplate.from_template("당신은 전문변호사 입니다. {law_name}과 {law_content}를 일반인이 보고 쉽게 이해할 수 있도록 2줄로 요약해주세요")

    chain = prompt | llm
    ai_message = chain.invoke(
        {
            "law_name": law_name,
            "law_content": law_content,
        }
    )
    return ai_message

def judge_guilty_or_not(result, explanation, user_situation):
    """법 설명에 기반하여 유죄 여부 판단"""
    law_name = result.metadata
    law_content = result.page_content

    prompt = PromptTemplate.from_template("당신은 전문판사 입니다. {law_name}과 {law_content} 가 {user_situation}와 관련이 있는지 확인하고 관련이 없다면 '관련이 없는 법입니다'. 대부분은 관련이 없어. 사용자의 직업, 장소 등을 고려해서 객관적으로 판단해. 관련이 있다면 사용자가 {law_content}를 위반했는지 여부를 판단하고, 위반 여부와 이유를 2줄로 설명해. ")

    chain = prompt | llm
    ai_message = chain.invoke(
        {   "user_situation": user_situation,
            "law_name": law_name,
            "law_content": law_content,
        }
    )
    return ai_message

# 판례 관련 기능
def answer_precedent(user_situation):
    """사용자 상황을 판시사항 형식으로 요약하여 판례 검색"""
    prompt = PromptTemplate.from_template("너는 판사야. {user_situation}의 글을 판시사항 형식으로 3줄 미만으로 요약해서 줘")

    chain = prompt | llm
    ai_message = chain.invoke(
        {"user_situation": user_situation}
    )
    print('변환된 사용자의 질문:', ai_message.content)
    print("----------------------------------------------------------------------------------")

    # ai_message.content를 검색에 사용
    search_with_ai = retriever_precedent.get_relevant_documents(ai_message.content)
    return search_with_ai

def ai_summary(content):
    #"""주어진 판례를 쉽게 이해할 수 있도록 1줄로 요약"""
    prompt = PromptTemplate.from_template("주어진 {content}는 판시사항이야. 일반인이 이해하기 쉽도록 쉬운 말로 1줄로 요약해")

    chain = prompt | llm
    ai_message = chain.invoke(
        {"content": content}
    )
    return ai_message

def yes_or_no(situation, precedent):
  #판례가 user 상황과 맞는지 판단
    prompt = PromptTemplate.from_template("yes 혹은 no로 대답해. 주어진 {situation}가 {pre}와 관련이 있는지 확인하고 yes , no로 대답해줘. 대부분은 관련이 없어. ")
    ai_message = []


    chain = prompt | llm
    for pre in precedent:

        ai_message.append((chain.invoke(
            {"situation": situation, "pre": pre}  # 'situation'과 'pre'를 모두 포함해서 전달
        )).content)

    return ai_message

# 메인 서비스
def main():
    service_choice = 0
    while service_choice != "3":
      # 서비스 선택
      print("어떤 서비스를 원하십니까?")
      print("1. 법률찾기")
      print("2. 판례찾기")
      print("3. 종료")
      service_choice = input("1,2 또는 3을 선택해주세요: ")

      if service_choice == "1":
          # 법률찾기
          user_situation = input("당신이 처한 상황에 대해 말해주세요: ")
          print("--------------------------------------------------------")

          search_result = retriever_1.get_relevant_documents(user_situation)

          for result in search_result:
              start_time = time.time()
              print('법률:', result.metadata)
              print('내용:', result.page_content)
              explanations = explain_law(result)
              judgments = judge_guilty_or_not(result, explanations, user_situation)
              print('법 설명입니다:', explanations.content)
              print('범죄 성립 유무입니다:', judgments.content)
              end_time = time.time()
              elapsed_time = end_time - start_time
              print(f"대답을 받는데 걸린 시간: {elapsed_time:.4f} 초")
              print("--------------------------------------------------------")

      elif service_choice == "2":
          # 판례찾기
          user_situation = input("검색할 판례의 내용을 입력하세요: ")
          print("--------------------------------------------------------")

          # AI 기반 판례 검색
          ai_search = answer_precedent(user_situation)
          # 일반 검색
          normall_search = retriever_precedent.get_relevant_documents(user_situation)

          # 검색 결과 합치기 (중복 제거)
          all_search = ai_search + normall_search

          #yes or no 만들기
          all_content = []

          for i in range(len(all_search)):
            all_content.append(all_search[i].page_content)


          answer = yes_or_no(user_situation, all_content)

          unique_content = []
          unique_link = []
          unique_answer = []


          # 중복된 내용 및 링크 제거
          for num in range(len(all_search)):
              if  all_search[num].page_content not in unique_content:
                  unique_content.append(all_search[num].page_content)
                  unique_answer.append(answer[num])
              if all_search[num].metadata['link'] not in unique_link:
                  unique_link.append(all_search[num].metadata['link'])

          # 내용 출력
          for i in range(len(unique_content)):
              print('내용:', unique_content[i])
              print('요약:', ai_summary(unique_content[i]).content)
              print('관련있는가:', unique_answer[i])
              print('URL:', unique_link[i])
              print("--------------------------------------------------------")

      elif service_choice == "3":
          print("프로그램을 종료합니다.")
          break

      else:
          print("잘못된 입력입니다. 1 또는 2를 선택해주세요.")

# 서비스 실행
if __name__ == "__main__":
    main()

"""#test streamlit"""

!pip install streamlit pyngrok

import streamlit as st
import time
from langchain_core.prompts import PromptTemplate

# 여기서는 기존의 함수들을 그대로 사용합니다. 예시로 일부 함수들만 정의했습니다. (설명과 판단, 판례 검색, 요약 등)

# 법률 관련 기능
def explain_law(search_result):
    """법 내용을 쉽게 요약하여 설명"""
    law_name = search_result.metadata
    law_content = search_result.page_content
    prompt = PromptTemplate.from_template("당신은 전문변호사 입니다. {law_name}과 {law_content}를 일반인이 보고 쉽게 이해할 수 있도록 2줄로 요약해주세요")

    chain = prompt | llm
    ai_message = chain.invoke(
        {"law_name": law_name, "law_content": law_content}
    )
    return ai_message

def judge_guilty_or_not(result, explanation, user_situation):
    """법 설명에 기반하여 유죄 여부 판단"""
    law_name = result.metadata
    law_content = result.page_content
    prompt = PromptTemplate.from_template("당신은 전문판사 입니다. {law_name}과 {law_content} 가 {user_situation}와 관련이 있는지 확인하고, 관련이 없다면 '관련이 없는 법입니다'라고 말해주세요.")

    chain = prompt | llm
    ai_message = chain.invoke(
        {"user_situation": user_situation, "law_name": law_name, "law_content": law_content}
    )
    return ai_message

# 판례 관련 기능
def answer_precedent(user_situation):
    """사용자 상황을 판시사항 형식으로 요약하여 판례 검색"""
    prompt = PromptTemplate.from_template("{user_situation}의 글을 판시사항 형식으로 요약해줘")
    chain = prompt | llm
    ai_message = chain.invoke({"user_situation": user_situation})
    search_with_ai = retriever_precedent.get_relevant_documents(ai_message.content)
    return search_with_ai

def ai_summary(content):
    """주어진 판례를 쉽게 이해할 수 있도록 1줄로 요약"""
    prompt = PromptTemplate.from_template("주어진 {content}는 판시사항이야. 일반인이 이해하기 쉽도록 1줄로 요약해")
    chain = prompt | llm
    ai_message = chain.invoke({"content": content})
    return ai_message

# Streamlit 앱
def app():
    st.title("법률 챗봇")

    # 서비스 선택
    service_choice = st.radio("어떤 서비스를 원하십니까?", ["법률 찾기", "판례 찾기"])

    if service_choice == "법률 찾기":
        # 법률 찾기
        user_situation = st.text_input("당신이 처한 상황을 설명해주세요:")

        if user_situation:
            search_result = retriever_1.get_relevant_documents(user_situation)

            for result in search_result:
                st.write(f"법률: {result.metadata}")
                st.write(f"내용: {result.page_content}")

                explanations = explain_law(result)
                judgments = judge_guilty_or_not(result, explanations, user_situation)

                st.write(f"법 설명: {explanations.content}")
                st.write(f"범죄 성립 유무: {judgments.content}")

    elif service_choice == "판례 찾기":
        # 판례 찾기
        user_situation = st.text_input("검색할 판례 내용을 입력하세요:")

        if user_situation:
            ai_search = answer_precedent(user_situation)
            normall_search = retriever_precedent.get_relevant_documents(user_situation)

            # 검색 결과 합치기 (중복 제거)
            all_search = ai_search + normall_search
            unique_content = []
            unique_link = []

            # 중복된 내용 및 링크 제거
            for result in all_search:
                if result.page_content not in unique_content:
                    unique_content.append(result.page_content)
                if result.metadata['link'] not in unique_link:
                    unique_link.append(result.metadata['link'])

            # 내용 출력
            for i in range(len(unique_content)):
                st.write(f"내용: {unique_content[i]}")
                st.write(f"요약: {ai_summary(unique_content[i]).content}")
                st.write(f"URL: {unique_link[i]}")

# Streamlit 앱 실행
if __name__ == "__main__":
    app()

from pyngrok import ngrok

# Streamlit 앱 실행
!streamlit run law_chatbot.py &

# ngrok을 사용해 로컬 서버를 공개
public_url = ngrok.connect(8501)
public_url

from pyngrok import ngrok

# Streamlit 앱 실행
!streamlit run your_file_name.py &

# ngrok을 사용해 로컬 서버를 공개
public_url = ngrok.connect(8501)
public_url

!streamlit app.py

